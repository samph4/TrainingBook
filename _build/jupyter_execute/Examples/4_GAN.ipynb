{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 - Generative Adversarial Network\n",
    "\n",
    "`github.com/samph4`\n",
    "\n",
    "~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preface\n",
    "\n",
    "This example will be more in-depth than the first few, but a lot of the principles that we have already applied also apply here. As always, we'll go through it step by step and I'll do my best to explain each part so that it makes sense and is as easy to follow as I can make it. In this final example, we will be looking at Generative Adversarial Networks - affectionately known as GANs. The concept of GANs were first introduced by Ian Goodfellow and his team in 2014 (https://arxiv.org/abs/1406.2661), where they \"proposed a new framework for estimating generative models via an an adversarial process\". I'll get into this in much more detail, but essentially what is happening here is that we are going to train two neural networks (that will be adversaries), that will compete against one another in order to improve. One will be reffered to as the Discriminator and the other will be known as the Generator. We combine both of these networks to form a combined model known as the GAN for training. Once training has been completed, we want to be able to use the *trained* Generator network independently to generate new things!\n",
    "\n",
    "![Image](./Figures/gan2.png)\n",
    "\n",
    "The image above looks rather unassuming, it is simply a row of portraits of four different people. The interesting thing however, is that none of these people actually exist. They are not real. Each of these images has been generated by a Generative Adversarial Network known as StyleGAN. StyleGAN is a sophisticated GAN that has been curated and trained by NVIDIA and represents the state-of-the-art results in data-driven unconditional generative image modelling and is an impressive testament as to the possibilities of Generative Networks. Here is another video that demonstrates the capabilities of these methods (which is only 2 minutes long so I recommend you watch it because it's v cool) - https://www.youtube.com/watch?v=p5U4NgVGAwg. With that being said, lets take a closer look as to how these things actually work.\n",
    "\n",
    "![Image](./Figures/gan1.png)\n",
    "\n",
    "~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Set\n",
    "\n",
    "First of all, we need to decide what we want our generative network to generate. Of course, NVIDIA's sophisticated StyleGAN is capable of generating human faces, but GANs are capable of generating new data regardless of the form that it comes in. GANs can be used to generate new audio signals, new images, new time-series data etc. GANs are capable of generating new data that is representative of the data that it was trained on (the training set). Therefore, in large, a key factor in the success of the GAN model lies in the quality of the training set. \n",
    "\n",
    "In this example we will \n",
    "\n",
    "`dataset = name of variable containing training set`\n",
    "\n",
    "```{note}\n",
    "Throughout this example I may use terms such as 'real' and 'fake' when referring to data. Real refers to data samples that come from the training set and 'fake' samples refer to any data that is produced by the Generator.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot\n",
    "from numpy.random import rand\n",
    "from numpy.random import randn\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LeakyReLU\n",
    "\n",
    "from keras import optimizers\n",
    "from keras import initializers\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Training (Target) Dataset\n",
    "\n",
    "Here we create a simple dataset that will be used to form the training set of real data. For simplicity, we will consider a simple y=sin(x) function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.23606797749979"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAD4CAYAAADhNOGaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAWiElEQVR4nO3df6xk5X3f8feHxag1cbq2ucbLryyNVlFp1WDrCieickwM7kLdLK4aCdK6yKq0ojIRdqs2pJGS7R+RUNqE4JjgbDDtWrWN3NjUK5fYxjQtcSsnLC7GizFhS3FZ75a9JsY/4j8Q3m//mHPDcLmzd+6emTtz5rxf0mjmnPOcme813vnOeZ7zfJ9UFZKk/jpj1gFIkmbLRCBJPWcikKSeMxFIUs+ZCCSp586cdQCn45xzzqmdO3fOOgxJ6pSHH374W1W1tHZ/JxPBzp07OXTo0KzDkKROSfKN9fbbNSRJPWcikKSeMxFIUs+ZCCSp50wEGs/amlTWqJIWxkQSQZK7k5xIcnjE8ST5QJIjSR5N8uahY7uTPNEcu2US8WjC9u2D97//pS//qsH2vn2zjErShEzqiuA/ALtPcfxqYFfz2AvcCZBkG3BHc/wS4Pokl0woJk1CFTz/PNx++0vJ4P3vH2w//7xXBtICmMg8gqp6MMnOUzTZA3ykBjWvv5Rke5IdwE7gSFU9BZDknqbt1yYRl4ZUQTJ6e5QEbrtt8Pr22wcPgJtvHuwf5z0kzbWtGiM4H3hmaPtos2/U/ldIsjfJoSSHVlZWphboQmrbtTOcDFaZBKSFsVWJYL1vjDrF/lfurNpfVctVtby09IoZ0hplEl07q+cMG04skjptq0pMHAUuHNq+ADgGnDVivyalbdfOcOJYPWd1G7wykBbAVl0RHAT+SXP30E8B36mq48BDwK4kFyc5C7iuaatJatO1k8D27S9PHLfdNtjevt0kIC2AiVwRJPk48DbgnCRHgV8DXgVQVR8C7gOuAY4APwDe0xx7MclNwOeAbcDdVfXYJGLSkFFdO+Mmg337Xj64vJoMNpMETnewWtLUTequoes3OF7Ae0ccu49BotA0TKprZ22bzXyJ79s3GI9Y/azVmLZvdy6CNAc6WYZamzCqawe2pmtneLAaXp6Ibr7ZKwNpDqQ6eOfH8vJyuR7BJs2ya2b4qmSV8xCkLZfk4apafsV+E4G2RBWcMXRvwsmTJgFpi41KBBad0/Q5D0GaayYCTdfaweqTJwfPwxPcJM2Ug8WarlkPVkvakGMEXdH1+/C7Hr+0ABwj6LJFWA+gzTwESVNlIph3rgcgacocI5h3rgcgacocI+gK78OX1JJjBF3mffiSpshEMO+8D1/SlDlGMO+8D1/SlDlG0BXehy+pJccIus778CVNyUQSQZLdSZ5IciTJLesc/5dJHmkeh5P8MMnrmmNPJ/lqc6xnP/M1trVXrh28kpXmVetEkGQbcAdwNXAJcH2SS4bbVNW/rapLq+pS4JeB/15Vfz7U5Irm+CsuWaSFmFktzbFJXBFcBhypqqeq6gXgHmDPKdpfD3x8Ap+rPnBmtTR1k7hr6HzgmaHto8Bb1muY5NXAbuCmod0FfD5JAb9XVftHnLsX2Atw0UUXTSBsdYIzq6Wpm8QVwXr/Ekf9TPv7wP9Y0y10eVW9mUHX0nuTvHW9E6tqf1UtV9Xy0tJSu4jVLcPJYJVJQJqYSSSCo8CFQ9sXAMdGtL2ONd1CVXWseT4B3Mugq0l6iTOrpamaRCJ4CNiV5OIkZzH4sj+4tlGSvwb8DPDpoX1nJ3nN6mvgHcDhCcSkReHMamnqWo8RVNWLSW4CPgdsA+6uqseS3Ngc/1DT9F3A56vqL4ZOPxe4N4NL/DOBj1XVZ9vGpAXizGpp6pxZrG5wZrXUmjOL1W3OrJamxkQgST1nIpCknjMRbBVr5UiaUyaCrWCtHElzzEQwbdbKkTTnXKFs2qyVI2nOOY9gq1TBGUMXYCdPmgQkbSnnEcyStXIkzTETwbRZK0fSnHOMYNqslSNpzjlGsFWslSNpxhwjmDVr5UiaUyYCSeo5E4Ek9dxEEkGS3UmeSHIkyS3rHH9bku8keaR5/Oq450qSpqv1XUNJtgF3AFcxWL/4oSQHq+pra5r+cVW98zTPlSRNySSuCC4DjlTVU1X1AnAPsGcLzpXGZ/VXaaRJJILzgWeGto82+9b66SRfSfKHSf7mJs8lyd4kh5IcWllZmUDY6g2rv0qnNIlEsN59kGt/bn0Z+LGq+kngd4D/vIlzBzur9lfVclUtLy0tnXaw6hmrv0obmsTM4qPAhUPbFwDHhhtU1XeHXt+X5HeTnDPOuVIrVn+VNjSJK4KHgF1JLk5yFnAdcHC4QZI3JoN/cUkuaz73uXHOlVobTgarTALSX2qdCKrqReAm4HPA48AnquqxJDcmubFp9g+Bw0m+AnwAuK4G1j23bUzSy1j9VTqliRSdq6r7gPvW7PvQ0OsPAh8c91xpYtZWf73ttpe2wSsDCauPatFZ/VXakNVH1Q9Wf5WsPqqes/qrNJKJQJJ6zkQgST1nIpCknjMRSFLPmQgkqedMBOOyjLGkBWUiGIdljCUtMBPBRixjLGnBWWJiI5YxlrTgLDExrio4Y+gC6uRJk4CkTrHERBuWMZa0wEwEG1lbxvjkycHz8JiBJHWYYwQbsYyxpAU3kTGCJLuB24FtwF1Vdeua4/8I+KVm8/vAP6uqrzTHnga+B/wQeHG9/qu1ZjZGYBljSR02aoyg9RVBkm3AHcBVDBajfyjJwar62lCz/wP8TFV9O8nVwH7gLUPHr6iqb7WNZaosYyxpQU1ijOAy4EhVPVVVLwD3AHuGG1TV/6yqbzebXwIumMDnSpImYBKJ4HzgmaHto82+Uf4p8IdD2wV8PsnDSfaOOinJ3iSHkhxaWVlpFbAk6SWTGCxer49k3YGHJFcwSAR/Z2j35VV1LMkbgPuTfL2qHnzFG1btZ9ClxPLysrfqSNKETOKK4Chw4dD2BcCxtY2S/G3gLmBPVT23ur+qjjXPJ4B7GXQ1SZK2yCQSwUPAriQXJzkLuA44ONwgyUXAp4B3V9WfDe0/O8lrVl8D7wAOTyAmSdKYWncNVdWLSW4CPsfg9tG7q+qxJDc2xz8E/CrweuB3M7jbZvU20XOBe5t9ZwIfq6rPto1JkjQ+aw1J43AeiRaAtYak0+V6FFpwJgLpVFyPQj1grSHpVFyPQj3gGIE0Dtej0AJwjEA6Xa5HoQVnIpBOxfUo1AOOEUin4noU6gHHCKRxOI9AC8AxAqkN16PQAjMRSFLPmQgkqedMBJLUcyYCSeo5E4Ek9ZyJQJJ6rj+JYO18iQ7On5DUY1P8DptIIkiyO8kTSY4kuWWd40nygeb4o0nePO65E2E9eUldNuXvsNaJIMk24A7gauAS4Pokl6xpdjWwq3nsBe7cxLntWE9eUpdtwXfYJGoNXQYcqaqnAJLcA+wBvjbUZg/wkRrUs/hSku1JdgA7xzi3HevJS+qyLfgOm0TX0PnAM0PbR5t947QZ51wAkuxNcijJoZWVlc1FOPw/5CqTgKSumPJ32CQSwXqRrL1WGdVmnHMHO6v2V9VyVS0vLS1tLkLryUvqsil/h00iERwFLhzavgA4Nmabcc5tx3rykrpsC77DJjFG8BCwK8nFwDeB64BfWNPmIHBTMwbwFuA7VXU8ycoY57ZjPXlJXbYF32ETWY8gyTXAbwPbgLur6teT3AhQVR9KEuCDwG7gB8B7qurQqHM3+rzTWo/AevKSumwC32Gj1iNwYRpJ6gkXppEkrctEIEk9ZyKQpJ4zEUhSz5kIJKnnTASS1HMmAmkruB6G5piJQJo218PQnDMRSNPkehjqgEnUGpI0iuthqAMsMSFthSo4Y+gC/ORJk4C2nCUmpFlxPQzNOROBNE2uh6EOcIxAmibXw1AHOEYgbQXXw9AccIxAmqW1X/omAc2RVokgyeuS3J/kyeb5teu0uTDJHyV5PMljSW4eOrYvyTeTPNI8rmkTjyRp89peEdwCPFBVu4AHmu21XgT+RVX9DeCngPcmuWTo+G1VdWnzuK9lPJKkTWqbCPYAB5rXB4Br1zaoquNV9eXm9feAx4HzW36uJGlC2iaCc6vqOAy+8IE3nKpxkp3Am4A/Gdp9U5JHk9y9XtfS0Ll7kxxKcmhlZaVl2JKkVRsmgiRfSHJ4nceezXxQkh8BPgm8r6q+2+y+E/hx4FLgOPCbo86vqv1VtVxVy0tLS5v5aEnSKWw4j6Cqrhx1LMmzSXZU1fEkO4ATI9q9ikES+GhVfWrovZ8davP7wGc2E7wkqb22XUMHgRua1zcAn17bIEmADwOPV9VvrTm2Y2jzXcDhlvFI0nya4zUp2iaCW4GrkjwJXNVsk+S8JKt3AF0OvBv42XVuE/2NJF9N8ihwBbCmIIskLYA5X5OiVYmJqnoOePs6+48B1zSvvwisO3umqt7d5vMlae4Nr0kBgxIjw/Wn5mCWubWGJGmaOrAmhbWGJGkrzMGaFNYakqRZmfM1KUwEkjRNHViTwjECSZqmDqxJ4RiBJG2FOViTwjECSZqlOV6TwkQgST1nIpCknjMRSFLPmQgkqedMBJLUcyYCqQvmuISxus9EIM27OS9hrO4zEUjzbLiE8WoyWC1X8PzzXhloIiwxIc2zDpQwVve1uiJI8rok9yd5snl+7Yh2TzcrkT2S5NBmz5d6bTgZrDIJaILadg3dAjxQVbuAB5rtUa6oqkvX1LnYzPlSP815CWN1X9tEsAc40Lw+AFy7xedLi60DJYzVfW3HCM6tquMAVXU8yRtGtCvg80kK+L2q2r/J80myF9gLcNFFF7UMW+qIDpQwVvdtWIY6yReAN65z6FeAA1W1fajtt6vqFf38Sc6rqmPNF/39wC9W1YNJnh/n/LUsQ63emYMSxuq+UWWoN7wiqKorT/GmzybZ0fya3wGcGPEex5rnE0nuBS4DHgTGOl/qvTkuYazuaztGcBC4oXl9A/DptQ2SnJ3kNauvgXcAh8c9X5I0XW0Twa3AVUmeBK5qtklyXpL7mjbnAl9M8hXgT4H/UlWfPdX5kqSt02qwuKqeA96+zv5jwDXN66eAn9zM+ZKkrWOJCUnqOROBJG1kwau/mggk6VR6UP3VRCBJo/Sk+qvVRyVplJ5Uf91wZvE8cmaxpC1VBWcMdaCcPNnJJDBqZrFdQ5J0Kj2o/moikKRRelL91TECSRqlJ9VfHSOQpI0sSPVXxwgk6XQtePVXE4Ek9ZyJQJJ6zkQg9cGC18pROyYCadH1oFaO2mmVCJK8Lsn9SZ5sntdbr/gnkjwy9Phukvc1x/Yl+ebQsWvaxCNpjZ7UylE7becR3AI8UFW3Jrml2f6l4QZV9QRwKUCSbcA3gXuHmtxWVf+uZRyS1tOTWjlqp23X0B7gQPP6AHDtBu3fDvzvqvpGy8+VNK7hZLDKJKAhbRPBuVV1HKB5fsMG7a8DPr5m301JHk1y93pdS6uS7E1yKMmhlZWVdlFLfdKDWjlqZ8NEkOQLSQ6v89izmQ9Kchbwc8B/Gtp9J/DjDLqOjgO/Oer8qtpfVctVtby0tLSZj5b6qye1ctTOhmMEVXXlqGNJnk2yo6qOJ9kBnDjFW10NfLmqnh167798neT3gc+MF7aksfSkVo7aaTtYfBC4Abi1ef70Kdpez5puodUk0my+CzjcMh5Ja+3b9/LaOKvJwCSgRtsxgluBq5I8CVzVbJPkvCT3rTZK8urm+KfWnP8bSb6a5FHgCmBNR6akiVjwWjlqp9UVQVU9x+BOoLX7jwHXDG3/AHj9Ou3e3ebzJWksC1I9dFqcWSxpsTmzekMmAkmLy5nVY3GFMkmLy5nVY3GFMkmLrwrOGOoAOXmyl0nAFcok9ZMzqzdkIpC0uJxZPRbHCCQtLmdWj8UxAkkb6/p9+F2Pf0IcI5B0ehbhPnxnVp+SiUDSaN6H3wuOEUgazfvwe8ExAkkb8z78heAYgaTTMw/34a/9rA7+gJ1nJgJJo83DffiLMFg95xwjkDTarO/DHx6shsFnDyemnt4GOmmOEUjaWNv78NucP3xVssrB6tMylTGCJD+f5LEkJ5O84s2H2u1O8kSSI0luGdr/uiT3J3myeX5tm3gkTUmb+/Dbdu0MX4WsMglMVNsxgsPAPwAeHNUgyTbgDgaL118CXJ/kkubwLcADVbULeKDZlrQoJjEPYR4Gqxdcq0RQVY9X1RMbNLsMOFJVT1XVC8A9wJ7m2B7gQPP6AHBtm3gkzZnVX/OrA8xnnPFS//44v+rnYbC6B7birqHzgWeGto82+wDOrarjAM3zG0a9SZK9SQ4lObSysjK1YCVNWJuunVGD1TffbNG4CdrwrqEkXwDeuM6hX6mqT4/xGev9l9p0Gq+q/cB+GAwWb/Z8STMyqmtn3GSwb9/LB5dXk4FJYGI2TARVdWXLzzgKXDi0fQFwrHn9bJIdVXU8yQ7gRMvPkjRP1nbtDN/+CZu7MjjVtlrZinkEDwG7klwMfBO4DviF5thB4Abg1uZ5nCsMSV0x63kIGkureQRJ3gX8DrAEPA88UlV/N8l5wF1VdU3T7hrgt4FtwN1V9evN/tcDnwAuAv4v8PNV9ecbfa7zCKSOcT2AuTBqHoETyiSpJyw6J0lal4lAknrORCBJPWcikKSe6+RgcZIV4Bunefo5wLcmGM4sdP1vMP7Z6/rf0PX4YTZ/w49V1dLanZ1MBG0kObTeqHmXdP1vMP7Z6/rf0PX4Yb7+BruGJKnnTASS1HN9TAT7Zx3ABHT9bzD+2ev639D1+GGO/obejRFIkl6uj1cEkqQhJgJJ6rleJYIku5M8keRIks6tj5zk7iQnkhyedSynI8mFSf4oyeNJHkty86xj2owkfyXJnyb5ShP/v5l1TKcjybYk/yvJZ2Ydy+lI8nSSryZ5JEnnqk8m2Z7kD5J8vfm38NMzj6kvYwRJtgF/BlzFYLGch4Drq+prMw1sE5K8Ffg+8JGq+luzjmezmsWHdlTVl5O8BngYuLYr/w2SBDi7qr6f5FXAF4Gbq+pLMw5tU5L8c2AZ+NGqeues49msJE8Dy1XVyQllSQ4Af1xVdyU5C3h1VT0/y5j6dEVwGXCkqp6qqheAe4A9M45pU6rqQWDD9RrmVVUdr6ovN6+/BzzOS+tXz70a+H6z+arm0alfUkkuAP4ecNesY+mjJD8KvBX4MEBVvTDrJAD9SgTnA88MbR+lQ19CiybJTuBNwJ/MNpLNabpVHmGwrOr9VdWp+BksEPWvgJOzDqSFAj6f5OEke2cdzCb9dWAF+PdN99xdSc6edVB9SgTrLYfUqV9ziyLJjwCfBN5XVd+ddTybUVU/rKpLGay9fVmSznTRJXkncKKqHp51LC1dXlVvBq4G3tt0mXbFmcCbgTur6k3AXwAzH6/sUyI4Clw4tH0BcGxGsfRW07f+SeCjVfWpWcdzuprL+f8G7J5xKJtxOfBzTR/7PcDPJvmPsw1p86rqWPN8AriXQbdvVxwFjg5dSf4Bg8QwU31KBA8Bu5Jc3AzQXAccnHFMvdIMtn4YeLyqfmvW8WxWkqUk25vXfxW4Evj6bKMaX1X9clVdUFU7Gfz//79W1T+ecVibkuTs5kYDmi6VdwCduYuuqv4f8EySn2h2vR2Y+c0SZ846gK1SVS8muQn4HLANuLuqHptxWJuS5OPA24BzkhwFfq2qPjzbqDblcuDdwFebfnaAf11V980wps3YARxo7kA7A/hEVXXyFswOOxe4d/CbgjOBj1XVZ2cb0qb9IvDR5gfpU8B7ZhxPf24flSStr09dQ5KkdZgIJKnnTASS1HMmAknqOROBJPWciUCSes5EIEk99/8BXG43pwGJ3KsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "filenames": {
       "image/png": "C:\\Users\\Samuel\\Documents\\samph4\\TrainingBook\\_build\\jupyter_execute\\Examples\\4_GAN_7_0.png"
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n1 = 20\n",
    "dataset = np.zeros((n1,2))\n",
    "dataset[:,0] = np.linspace(0,2*np.pi,n1)\n",
    "dataset[:,1] = np.sin(dataset[:,0])\n",
    "\n",
    "pyplot.scatter(dataset[:,0],dataset[:,1], marker='x',color='r')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Take Real Samples\n",
    "To evaluate the performance of the GAN we will use the real data from the training set to train the Discriminator so that it can learn the characteristics of data that comes from the training set. This will make it easier for the Discriminator to label samples that come from the Generator as fake. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def take_real_samples(n):\n",
    "    np.random.seed(30)\n",
    "    idx = np.random.randint(len(dataset), size=int(n))\n",
    "    X = dataset[idx,:]\n",
    "    y = np.ones((n,1)) \n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate points in latent space as input for the generator\n",
    "\n",
    "Next, we can use the generator model to generate fake samples. Although first we need to generate points in latent space via the `generate_latent_points()` function below. These can then be passed to the generator model and used to generate new samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate points in latent space as input for the generator\n",
    "def create_latent_points(latent_dim, n):\n",
    "    # generate points in the latent space\n",
    "    x_input = randn(latent_dim * n)\n",
    "    # reshape into a batch of inputs for the network\n",
    "    x_input = x_input.reshape(n, latent_dim)\n",
    "    return x_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use the Generator to generate n fake examples, with class labels\n",
    "\n",
    "The `generate_fake_samples()` function below inputs the latent variables created by the `generate_latent_points()` function into the generator network to generate n fake samples `X`. Class labels of 0's are assigned to variable `y` to label the fake samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the generator to generate n fake examples, with class labels\n",
    "def generate_fake_samples(generator, latent_dim, n):\n",
    "    # generate points in latent space\n",
    "    x_input = create_latent_points(latent_dim, n)\n",
    "    # predict outputs\n",
    "    X = generator.predict(x_input)\n",
    "    # create class labels\n",
    "    y = np.zeros((n, 1))\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define GAN Model\n",
    "\n",
    "#### Discrimnator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_discriminator(n_inputs=2):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(25,  kernel_initializer='he_uniform', input_dim=n_inputs))\n",
    "    model.add(LeakyReLU(alpha=0.01))\n",
    "    model.add(Dense(15,  kernel_initializer='he_uniform'))\n",
    "    model.add(LeakyReLU(alpha=0.01))\n",
    "    model.add(Dense(10,  kernel_initializer='he_uniform'))\n",
    "    model.add(LeakyReLU(alpha=0.01))\n",
    "    model.add(Dense(5,  kernel_initializer='he_uniform'))\n",
    "    model.add(LeakyReLU(alpha=0.01))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    # compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the standalone generator model\n",
    "def define_generator(latent_dim, n_outputs=2):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(15, activation='relu', kernel_initializer='he_uniform', input_dim=latent_dim))\n",
    "    model.add(Dense(n_outputs, activation='linear'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combined GAN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the combined generator and discriminator model, for updating the generator\n",
    "def define_gan(generator, discriminator):\n",
    "    # make weights in the discriminator not trainable\n",
    "    discriminator.trainable = False\n",
    "    # connect them\n",
    "    model = Sequential()\n",
    "    # add generator\n",
    "    model.add(generator)\n",
    "    # add the discriminator\n",
    "    model.add(discriminator)\n",
    "    # compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the discriminator and plot real and fake points\n",
    "def summarize_performance(epoch, generator, discriminator, latent_dim, n=100):\n",
    "    # prepare real samples\n",
    "    x_real, y_real = take_real_samples(n)\n",
    "    # evaluate discriminator on real examples\n",
    "    _, acc_real = discriminator.evaluate(x_real, y_real, verbose=0)\n",
    "    # prepare fake examples\n",
    "    x_fake, y_fake = generate_fake_samples(generator, latent_dim, n)\n",
    "    # evaluate discriminator on fake examples\n",
    "    _, acc_fake = discriminator.evaluate(x_fake, y_fake, verbose=0)\n",
    "    # summarize discriminator performance\n",
    "    print(epoch+1, acc_real, acc_fake)\n",
    "    # scatter plot real and fake data points\n",
    "    \n",
    "    \n",
    "    pyplot.scatter(x_real[:, 0], x_real[:, 1], marker='x', color='red')\n",
    "    pyplot.scatter(x_fake[:, 0], x_fake[:, 1], marker='$\\u25EF$', color='grey')\n",
    "    pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the generator and discriminator\n",
    "def train(g_model, d_model, gan_model, latent_dim, n_epochs=20000, n_batch=1024, n_eval=1000):\n",
    "    # determine half the size of one batch, for updating the discriminator\n",
    "    half_batch = int(n_batch / 2)\n",
    "    # manually enumerate epochs\n",
    "    for i in range(n_epochs):\n",
    "        # prepare real samples\n",
    "        x_real, y_real = take_real_samples(half_batch)\n",
    "        # prepare fake examples\n",
    "        x_fake, y_fake = generate_fake_samples(g_model, latent_dim, half_batch)\n",
    "        # update discriminator\n",
    "        d_model.train_on_batch(x_real, y_real)\n",
    "        d_model.train_on_batch(x_fake, y_fake)\n",
    "        # prepare points in latent space as input for the generator\n",
    "        x_gan = create_latent_points(latent_dim, n_batch)\n",
    "        # create inverted labels for the fake samples\n",
    "        y_gan = np.ones((n_batch, 1))\n",
    "        # update the generator via the discriminator's error\n",
    "        gan_model.train_on_batch(x_gan, y_gan)\n",
    "        # evaluate the model every n_eval epochs\n",
    "        if (i+1) % n_eval == 0:\n",
    "            summarize_performance(i, g_model, d_model, latent_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "InternalError",
     "evalue": " Blas GEMM launch failed : a.shape=(32, 5), b.shape=(5, 15), m=32, n=15, k=5\n\t [[node dense_6/MatMul (defined at C:\\Users\\Samuel\\miniconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3009) ]] [Op:__inference_keras_scratch_graph_377]\n\nFunction call stack:\nkeras_scratch_graph\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-3db7c9b9c7df>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mgan_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdefine_gan\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m# train model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgan_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlatent_dim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-11-21e0732ec1cf>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(g_model, d_model, gan_model, latent_dim, n_epochs, n_batch, n_eval)\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mx_real\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_real\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtake_real_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhalf_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[1;31m# prepare fake examples\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[0mx_fake\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_fake\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgenerate_fake_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mg_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlatent_dim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhalf_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m         \u001b[1;31m# update discriminator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0md_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_real\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_real\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-09e284b18cef>\u001b[0m in \u001b[0;36mgenerate_fake_samples\u001b[1;34m(generator, latent_dim, n)\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mx_input\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_latent_points\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlatent_dim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;31m# predict outputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_input\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[1;31m# create class labels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1460\u001b[0m                                             \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1461\u001b[0m                                             \u001b[0msteps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1462\u001b[1;33m                                             callbacks=callbacks)\n\u001b[0m\u001b[0;32m   1463\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1464\u001b[0m     def train_on_batch(self, x, y,\n",
      "\u001b[1;32m~\\miniconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mpredict_loop\u001b[1;34m(model, f, ins, batch_size, verbose, steps, callbacks)\u001b[0m\n\u001b[0;32m    322\u001b[0m             \u001b[0mbatch_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'batch'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbatch_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'size'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    323\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'predict'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'begin'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 324\u001b[1;33m             \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    325\u001b[0m             \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    326\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3725\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3726\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3727\u001b[1;33m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3728\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3729\u001b[0m     \u001b[1;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1549\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1550\u001b[0m     \"\"\"\n\u001b[1;32m-> 1551\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1552\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1553\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1589\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[0;32m   1590\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[1;32m-> 1591\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1592\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1593\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1690\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1692\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\miniconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m     \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m     keras_symbolic_tensors = [\n",
      "\u001b[1;32m~\\miniconda3\\envs\\tensorflow\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "\u001b[1;31mInternalError\u001b[0m:  Blas GEMM launch failed : a.shape=(32, 5), b.shape=(5, 15), m=32, n=15, k=5\n\t [[node dense_6/MatMul (defined at C:\\Users\\Samuel\\miniconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3009) ]] [Op:__inference_keras_scratch_graph_377]\n\nFunction call stack:\nkeras_scratch_graph\n"
     ]
    }
   ],
   "source": [
    "# size of the latent space\n",
    "latent_dim = 5\n",
    "# create the discriminator\n",
    "discriminator = define_discriminator()\n",
    "# create the generator\n",
    "generator = define_generator(latent_dim)\n",
    "# create the gan\n",
    "gan_model = define_gan(generator, discriminator)\n",
    "# train model\n",
    "train(generator, discriminator, gan_model, latent_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3.7 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}